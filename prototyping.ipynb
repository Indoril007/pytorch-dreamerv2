{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffa8e9-5faa-4f1a-b0a5-6da0b5dff5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import gym\n",
    "import safety_gym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "from garage.envs import GymEnv\n",
    "\n",
    "sys.path.append('../robust_rewards_from_preferences')\n",
    "import envs.custom_safety_envs\n",
    "del sys.path[-1]\n",
    "\n",
    "from replay_buffer import ReplayBuffer\n",
    "from garage.trainer import Trainer\n",
    "from dreamer import Dreamer\n",
    "from utils import RandomPolicy\n",
    "from garage.experiment.experiment import ExperimentContext\n",
    "from garage.sampler import RaySampler, LocalSampler, DefaultWorker\n",
    "import gym.envs.atari\n",
    "from garage.sampler.worker_factory import WorkerFactory\n",
    "import threading\n",
    "\n",
    "import torch\n",
    "\n",
    "from ruamel.yaml import YAML\n",
    "from dotmap import DotMap\n",
    "\n",
    "from garage import EpisodeBatch, TimeStepBatch\n",
    "from garage.envs.wrappers import ClipReward, EpisodicLife,  FireReset, Grayscale,  MaxAndSkip, Noop,  Resize, StackFrames\n",
    "from wrappers import Renderer\n",
    "\n",
    "import os\n",
    "from garage.experiment.deterministic import set_seed\n",
    "import pickle\n",
    "from models import WorldModel\n",
    "from garage.torch import set_gpu_mode\n",
    "\n",
    "import dowel\n",
    "from dowel import logger, tabular\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60b7026-e63d-4037-b463-1d4d631b6907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1756"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "600+34*34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4727d8aa-cf3b-447e-8198-680e781b2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(input_shape=1756, out_shape=64, units=[400, 400, 400, 400], dist='gaussian', ind_dims=1, scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1f9a3b-82e9-40ed-bef2-5f24e508a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03af60-f9a6-4140-bf6b-c83bb0e103fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minerl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67cecbc-f8a3-413d-a7f0-d5c7e5d7a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MineRLTreechopVectorObf-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2b415-3948-4413-ac6e-c0c410c2dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ed2018d-7826-4be2-b5da-53da78eb66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mlp.net.out_layer.bias.data = torch.nn.Parameter(torch.ones(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4832b8e2-ca93-4b46-a309-30366ee314b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.net.out_layer.bias.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e564838f-dc04-4526-bbca-50f2577e4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5cee333-96db-4d69-91a9-0f3c698cc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_config, get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104712cd-3ed9-440d-9c62-47a1c33a941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config('defaults')\n",
    "CONFIG = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd87cc49-e8c0-4480-a034-d29e5d4595e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logger.add_output(\n",
    "#     dowel.WandbOutput(\n",
    "#         project='dreamer',\n",
    "#         name='JUPYTER_RUN',\n",
    "#         config=CONFIG,\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297b4187-f715-4865-8fc4-c4f4c6cf4a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesborg/.pyenv/versions/3.8.7/envs/garage_2021.03/lib/python3.8/site-packages/garage/experiment/deterministic.py:36: UserWarning: Enabeling deterministic mode in PyTorch can have a performance impact when using GPU.\n",
      "  warnings.warn(\n",
      "/home/jamesborg/.pyenv/versions/3.8.7/envs/garage_2021.03/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ctxt = ExperimentContext(snapshot_dir='./snapshot_dir', snapshot_mode='gap_overwrite', snapshot_gap=50)\n",
    "snapshot_dir = ctxt.snapshot_dir\n",
    "\n",
    "env = gym.envs.atari.AtariEnv(\n",
    "    CONFIG.env.name, obs_type='image', frameskip=1,\n",
    "    repeat_action_probability=0.25, full_action_space=False)\n",
    "env = Noop(env, noop_max=30)\n",
    "env = MaxAndSkip(env, skip=4)\n",
    "# env = EpisodicLife(env)\n",
    "if CONFIG.image.color_channels == 1:\n",
    "    env = Grayscale(env)\n",
    "env = Resize(env, CONFIG.image.height, CONFIG.image.height)\n",
    "max_episode_length = 108000 / 4\n",
    "env = Renderer(env, directory=os.path.join(snapshot_dir, 'videos'))\n",
    "env = GymEnv(env, max_episode_length=max_episode_length, is_image=True)\n",
    "\n",
    "set_seed(CONFIG.training.seed)\n",
    "\n",
    "with open(os.path.join(snapshot_dir, 'env.pkl'), 'wb') as outfile:\n",
    "    pickle.dump(env, outfile)\n",
    "\n",
    "trainer = Trainer(ctxt)\n",
    "\n",
    "buf = ReplayBuffer(env.spec)\n",
    "policy = RandomPolicy(env.spec)\n",
    "world_model = WorldModel(env.spec)\n",
    "\n",
    "if CONFIG.training.sampler == \"ray\":\n",
    "    Sampler = RaySampler\n",
    "elif CONFIG.training.sampler == \"local\":\n",
    "    Sampler = LocalSampler\n",
    "\n",
    "sampler = Sampler(agents=policy,  # noqa: F841\n",
    "                  envs=env,\n",
    "                  max_episode_length=max_episode_length,\n",
    "                  n_workers=4)\n",
    "\n",
    "log_sampler = Sampler(agents=policy,  # noqa: F841\n",
    "                  envs=env,\n",
    "                  max_episode_length=max_episode_length,\n",
    "                  n_workers=4)\n",
    "\n",
    "#     log_sampler = Sampler(agents=policy,  # noqa: F841\n",
    "#                           envs=env,\n",
    "#                           max_episode_length=kwargs['max_episode_length'],\n",
    "#                           n_workers=kwargs['n_workers'])\n",
    "\n",
    "set_gpu_mode(False)\n",
    "\n",
    "algo = Dreamer(\n",
    "    env.spec,\n",
    "    sampler=sampler,\n",
    "    log_sampler=log_sampler,\n",
    "    world_model=world_model,\n",
    "    agent=policy,\n",
    "    buf=buf,\n",
    ")\n",
    "\n",
    "trainer.setup(\n",
    "    algo=algo,\n",
    "    env=env,\n",
    ")\n",
    "\n",
    "# trainer.train(n_epochs=CONFIG.training.n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c7b12e-fd5f-486d-afa1-08291472ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo._initialize_dataset(trainer)\n",
    "segs = algo.buffer.sample_segments(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2550e3ed-aae5-41b5-b5e8-3761f804ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from garage.torch import global_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67bd5003-ae37-40f1-9479-53d19d4c17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segs_to_batch(segs, env_spec):\n",
    "    device = global_device()\n",
    "    start = time.time()\n",
    "    actions = torch.tensor(\n",
    "        [env_spec.action_space.flatten_n(seg.actions) for seg in segs]\n",
    "    ).type(torch.float).to(device)\n",
    "    rewards = torch.tensor(\n",
    "        [seg.rewards for seg in segs]).type(torch.float).to(device)\n",
    "    \n",
    "    discounts = (\n",
    "        1 - torch.tensor([seg.terminals for seg in segs]).type(torch.float)\n",
    "    ).to(device)\n",
    "    print(time.time() -start)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    obs = torch.tensor(\n",
    "        [seg.next_observations for seg in segs]).type(torch.float).to(device)\n",
    "    print(time.time() -start)\n",
    "    \n",
    "    if CONFIG.image.color_channels == 1:\n",
    "        obs = obs.unsqueeze(2)\n",
    "    obs = obs / 255 - 0.5\n",
    "\n",
    "    return obs, actions, rewards, discounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3cd93855-90b9-4e3b-80fb-27f0bd0b2a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28697943687438965\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "A = torch.tensor(np.random.rand(50, 50, 64, 64))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf7d147b-0d46-4565-aefd-2fe110a046c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002048"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.element_size() * A.nelement() / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b510907-c428-4372-8661-6b47432366af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 64, 64]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "302d9f8f-7548-4210-b91f-3ed12b9c2e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 64, 64])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reshape([10, 5] + list(A.shape)[1:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3895e1e5-d689-411f-b30f-885280bba6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 64, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs[0].observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "910a75d9-62f1-4d93-8f3e-eea9519f2e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819200000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200000 * 64 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2925f2-5fbc-4e5b-b0d9-5a4f44b0b112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:52: LoggerWarning: \u001b[33mNo outputs have been added to the logger.\u001b[0m\n",
      "  logger.log('INITIALIZING')\n",
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:52: LoggerWarning: \u001b[33mLog data of type str was not accepted by any output\u001b[0m\n",
      "  logger.log('INITIALIZING')\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/jamesborg/workspace/research/dreamer/dreamer.py:74: LoggerWarning: \u001b[33mLog data of type TabularInput was not accepted by any output\u001b[0m\n",
      "  logger.log(tabular)\n",
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:76: TabularInputWarning: \u001b[33mTabularInput {Buffer/BufferSize: type(int)} was not accepted by any output\u001b[0m\n",
      "  tabular.clear()\n",
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:76: TabularInputWarning: \u001b[33mTabularInput {world_modelkl_loss: type(Tensor)} was not accepted by any output\u001b[0m\n",
      "  tabular.clear()\n",
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:76: TabularInputWarning: \u001b[33mTabularInput {world_modelreward_loss: type(Tensor)} was not accepted by any output\u001b[0m\n",
      "  tabular.clear()\n",
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:76: TabularInputWarning: \u001b[33mTabularInput {world_modeldiscount_loss: type(Tensor)} was not accepted by any output\u001b[0m\n",
      "  tabular.clear()\n",
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:76: TabularInputWarning: \u001b[33mTabularInput {world_modelrecon_loss: type(Tensor)} was not accepted by any output\u001b[0m\n",
      "  tabular.clear()\n",
      "/home/jamesborg/workspace/research/dreamer/dreamer.py:76: TabularInputWarning: \u001b[33mTabularInput {world_modeltotal_loss: type(Tensor)} was not accepted by any output\u001b[0m\n",
      "  tabular.clear()\n",
      "100%|██████████| 10/10 [03:36<00:00, 21.62s/it]\n",
      "/home/jamesborg/.pyenv/versions/3.8.7/envs/garage_2021.03/lib/python3.8/site-packages/garage/trainer.py:455: TabularInputWarning: \u001b[33mTabularInput {TotalEnvSteps: type(int)} was not accepted by any output\u001b[0m\n",
      "  tabular.clear()\n",
      "100%|██████████| 10/10 [03:40<00:00, 22.01s/it]\n",
      "100%|██████████| 10/10 [04:30<00:00, 27.01s/it]\n",
      "100%|██████████| 10/10 [05:01<00:00, 30.18s/it]\n",
      "100%|██████████| 10/10 [05:08<00:00, 30.86s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ef35d6-568a-4487-beb1-42205ea1779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = algo._sampler.obtain_exact_episodes(n_eps_per_worker=1, agent_update=algo.agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbf43897-8e90-466b-ac23-2210eb370360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866, 64, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps.observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "949c62c0-67b0-4968-9f8f-9552b1828643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866, 64, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps.next_observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "390fd0c2-bbd2-4946-9e08-af8a38769679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps.actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b1aa1dc-1d81-4aa0-8fef-109382863a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0.) * torch.log(torch.tensor(0.) / torch.tensor(0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bffefdc8-a2be-4ffa-bffc-b801c747c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.tensor(eps.observations).type(torch.float).unsqueeze(1).unsqueeze(0)\n",
    "actions = torch.tensor(env.spec.action_space.flatten_n(eps.actions)).type(torch.float).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02f51ccd-7a3d-4013-b6b2-282d25c0781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0181, 0.0091, 0.0142,  ..., 0.0335, 0.0637, 0.0077],\n",
       "         [0.0507, 0.0030, 0.0222,  ..., 0.0159, 0.0109, 0.1066],\n",
       "         [0.0108, 0.0219, 0.0412,  ..., 0.0142, 0.0173, 0.0691],\n",
       "         ...,\n",
       "         [0.0144, 0.0265, 0.0157,  ..., 0.0069, 0.0612, 0.0121],\n",
       "         [0.0477, 0.0194, 0.0428,  ..., 0.0613, 0.0289, 0.0058],\n",
       "         [0.0487, 0.0028, 0.0134,  ..., 0.0307, 0.0822, 0.0255]]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['posteriors'][0]['dist'].probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86d72fc6-0b13-44e1-a01b-c0fac372e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['posteriors'][50]['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed6aa218-4049-425d-84d9-b6bd2b1a9148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0178, 0.0095, 0.0144,  ..., 0.0343, 0.0614, 0.0078],\n",
       "         [0.0526, 0.0030, 0.0212,  ..., 0.0164, 0.0112, 0.1078],\n",
       "         [0.0114, 0.0222, 0.0398,  ..., 0.0144, 0.0183, 0.0682],\n",
       "         ...,\n",
       "         [0.0146, 0.0276, 0.0159,  ..., 0.0069, 0.0636, 0.0123],\n",
       "         [0.0477, 0.0193, 0.0427,  ..., 0.0597, 0.0286, 0.0059],\n",
       "         [0.0462, 0.0029, 0.0137,  ..., 0.0311, 0.0846, 0.0257]]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['posteriors'][50]['dist'].probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806ceba-4869-4103-ac64-bd0316db4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs, steps, channels, height, width = observations.shape\n",
    "flattened_observations = observations.reshape(\n",
    "    segs*steps, channels, height, width)\n",
    "embedded_observations = self.image_encoder(\n",
    "    flattened_observations).reshape(segs, steps, -1)\n",
    "out = self.rssm.observe(embedded_observations, actions)\n",
    "out['reward_dist'] = self.reward_predictor(out['feats'])\n",
    "out['discount_dist'] = self.discount_predictor(out['feats'])\n",
    "flattened_feats = out['feats'].reshape(segs*steps, self.feat_size)\n",
    "mean = self.image_decoder(flattened_feats).reshape(\n",
    "    segs, steps, channels, height, width)\n",
    "norm = distributions.Normal(loc=mean, scale=1)\n",
    "image_recon_dist = distributions.Independent(norm, 3)\n",
    "assert image_recon_dist.batch_shape == (segs, steps)\n",
    "out['image_recon_dist'] = image_recon_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd244602-0bf0-4a38-89f8-d842f82892c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_recon = world_model.reconstruct(obs, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57e06e3d-869d-43bf-a1e7-a95925863166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4819, 0.4742, 0.4841,  ..., 0.4814, 0.4772, 0.4791],\n",
       "          [0.4779, 0.4799, 0.4760,  ..., 0.4756, 0.4774, 0.4743],\n",
       "          [0.4827, 0.4746, 0.4826,  ..., 0.4808, 0.4761, 0.4799],\n",
       "          ...,\n",
       "          [0.4764, 0.4827, 0.4769,  ..., 0.4790, 0.4789, 0.4765],\n",
       "          [0.4774, 0.4763, 0.4792,  ..., 0.4731, 0.4783, 0.4730],\n",
       "          [0.4797, 0.4835, 0.4845,  ..., 0.4768, 0.4787, 0.4777]]],\n",
       "\n",
       "\n",
       "        [[[0.4819, 0.4744, 0.4840,  ..., 0.4815, 0.4773, 0.4794],\n",
       "          [0.4779, 0.4800, 0.4760,  ..., 0.4755, 0.4773, 0.4744],\n",
       "          [0.4828, 0.4745, 0.4828,  ..., 0.4809, 0.4762, 0.4798],\n",
       "          ...,\n",
       "          [0.4763, 0.4832, 0.4774,  ..., 0.4795, 0.4791, 0.4764],\n",
       "          [0.4775, 0.4761, 0.4793,  ..., 0.4730, 0.4782, 0.4730],\n",
       "          [0.4798, 0.4836, 0.4846,  ..., 0.4766, 0.4786, 0.4776]]],\n",
       "\n",
       "\n",
       "        [[[0.4818, 0.4742, 0.4840,  ..., 0.4812, 0.4770, 0.4794],\n",
       "          [0.4778, 0.4798, 0.4764,  ..., 0.4753, 0.4772, 0.4743],\n",
       "          [0.4826, 0.4748, 0.4829,  ..., 0.4812, 0.4763, 0.4797],\n",
       "          ...,\n",
       "          [0.4766, 0.4830, 0.4769,  ..., 0.4784, 0.4789, 0.4766],\n",
       "          [0.4773, 0.4761, 0.4793,  ..., 0.4732, 0.4781, 0.4729],\n",
       "          [0.4798, 0.4835, 0.4849,  ..., 0.4773, 0.4785, 0.4777]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.4820, 0.4743, 0.4840,  ..., 0.4814, 0.4773, 0.4793],\n",
       "          [0.4778, 0.4799, 0.4762,  ..., 0.4756, 0.4778, 0.4745],\n",
       "          [0.4829, 0.4744, 0.4828,  ..., 0.4809, 0.4760, 0.4798],\n",
       "          ...,\n",
       "          [0.4767, 0.4833, 0.4772,  ..., 0.4786, 0.4789, 0.4761],\n",
       "          [0.4772, 0.4760, 0.4793,  ..., 0.4733, 0.4780, 0.4728],\n",
       "          [0.4798, 0.4836, 0.4846,  ..., 0.4768, 0.4783, 0.4775]]],\n",
       "\n",
       "\n",
       "        [[[0.4819, 0.4743, 0.4838,  ..., 0.4814, 0.4772, 0.4792],\n",
       "          [0.4779, 0.4800, 0.4765,  ..., 0.4753, 0.4776, 0.4743],\n",
       "          [0.4827, 0.4747, 0.4829,  ..., 0.4808, 0.4761, 0.4796],\n",
       "          ...,\n",
       "          [0.4765, 0.4832, 0.4774,  ..., 0.4789, 0.4791, 0.4760],\n",
       "          [0.4776, 0.4760, 0.4793,  ..., 0.4733, 0.4784, 0.4730],\n",
       "          [0.4796, 0.4835, 0.4847,  ..., 0.4768, 0.4785, 0.4776]]],\n",
       "\n",
       "\n",
       "        [[[0.4820, 0.4741, 0.4841,  ..., 0.4813, 0.4771, 0.4793],\n",
       "          [0.4779, 0.4799, 0.4760,  ..., 0.4753, 0.4775, 0.4744],\n",
       "          [0.4827, 0.4746, 0.4825,  ..., 0.4811, 0.4758, 0.4796],\n",
       "          ...,\n",
       "          [0.4762, 0.4829, 0.4770,  ..., 0.4786, 0.4788, 0.4764],\n",
       "          [0.4772, 0.4762, 0.4792,  ..., 0.4732, 0.4782, 0.4730],\n",
       "          [0.4797, 0.4836, 0.4848,  ..., 0.4769, 0.4785, 0.4776]]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac6932ce-ba8d-41b6-a86d-81ed43530cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180, 155, 177, 199], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps.lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56e6799f-5911-49a8-ab7b-6b1d2365ab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88836146-32a8-4adc-a8eb-91b75152f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import log_reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88df2bb6-42ce-4485-8ab2-c62c0681257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reconstructions(eps, env.spec, world_model, 1, os.path.join(snapshot_dir, 'videos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f09604e9-0b2d-4a03-8e3f-73cf6e6f641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video import export_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d84c10ad-1f68-4106-8df8-143e355aaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_video(np.tile(eps.observations[:146, ..., np.newaxis], (1, 1, 1, 3)), './video1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b68b27ba-e5f8-44fa-9364-f76d67fb0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3132083b-f75c-4ae2-a74a-03f4b2545a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './snapshot_dir/videos/reconstructed_1_0.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aff72158-9473-4541-9bed-446a15adef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({os.path.basename(fname): wandb.Video(fname),}, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7805dea-20a2-46e3-abcf-31127cacafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 64, 64, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd9a68f4-87da-4e13-9986-93367999c6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 64, 64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps.observations[:146].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bca83ac-52c4-4b69-a964-1714a66ffdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 844, 1, 64, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c59876-b308-45ba-8fdf-fa63c0ba9bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minerl]",
   "language": "python",
   "name": "conda-env-minerl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
